#!/bin/bash
# Medical AI Development Environment Startup
#
# Ultra-short startup script for the complete medical AI development stack:
# - LMStudio Server (localhost:1234) with dual model loading
# - MLX Whisper Server (localhost:8001) - Audio transcription  
# - DSPy Server (localhost:8002) - Prompt optimization and evaluation
# 
# Usage:
#   ./dev
#
# This script will:
# 1. Start LMStudio server and load both medical models via CLI
# 2. Start MLX Whisper server for transcription
# 3. Start DSPy server for optimization
# 4. Verify all services are healthy
# 5. Display comprehensive status dashboard

# Note: set -e removed to allow graceful degradation when services fail
# Each service failure is handled explicitly to allow partial success

# macOS-compatible timeout function
run_with_timeout() {
    local timeout_duration=$1
    shift

    # Use gtimeout if available (from coreutils), otherwise use built-in timeout if available
    if command -v gtimeout >/dev/null 2>&1; then
        gtimeout "$timeout_duration" "$@"
    elif command -v timeout >/dev/null 2>&1; then
        timeout "$timeout_duration" "$@"
    else
        # Fallback: run without timeout on macOS
        "$@"
    fi
}

# Colors for output
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m'

log() {
    echo -e "${GREEN}[Dev Environment]${NC} $1"
}

warn() {
    echo -e "${YELLOW}[Dev Environment] WARNING:${NC} $1"
}

error() {
    echo -e "${RED}[Dev Environment] ERROR:${NC} $1"
}

info() {
    echo -e "${BLUE}[Dev Environment] INFO:${NC} $1"
}

success() {
    echo -e "${PURPLE}[Dev Environment] SUCCESS:${NC} $1"
}

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
OPERATOR_INGEST_VENV="$SCRIPT_DIR/mac_daemon/.venv-ingest"
OPERATOR_INGEST_REQ="$SCRIPT_DIR/mac_daemon/requirements.txt"

# Check if service is running on a port
check_port() {
    local port=$1
    local service_name=$2
    
    if lsof -i ":$port" > /dev/null 2>&1; then
        return 0  # Port is in use
    else
        return 1  # Port is free
    fi
}

# Check service health via HTTP
check_service_health() {
    local url=$1
    local timeout=${2:-5}
    
    if curl -s -f --max-time $timeout "$url" > /dev/null 2>&1; then
        return 0  # Service is healthy
    else
        return 1  # Service is unhealthy
    fi
}

# Cleanup background jobs (prevents zombie processes)
cleanup_background_jobs() {
    local load_pid=$1
    local progress_pid=$2

    # Stop load process if running
    if [ -n "$load_pid" ] && kill -0 "$load_pid" 2>/dev/null; then
        kill -TERM "$load_pid" 2>/dev/null || true
        sleep 0.5
        kill -KILL "$load_pid" 2>/dev/null || true
        wait "$load_pid" 2>/dev/null || true
    fi

    # Stop progress indicator
    if [ -n "$progress_pid" ] && kill -0 "$progress_pid" 2>/dev/null; then
        kill -TERM "$progress_pid" 2>/dev/null || true
        wait "$progress_pid" 2>/dev/null || true
    fi
}

# Cleanup temporary files on exit
cleanup_on_exit() {
    # Clean up any temp files matching our pattern (older than 60 minutes)
    find /tmp -maxdepth 1 -name "whisper-startup-*.log" -user $(whoami) -mmin +60 -delete 2>/dev/null || true
}

# Check if lms CLI is available
check_lms_cli() {
    if ! command -v lms &> /dev/null; then
        warn "LMStudio CLI (lms) not found in PATH"
        warn "Please install LMStudio CLI: https://lmstudio.ai/docs/cli"
        warn "Or bootstrap: ~/.lmstudio/bin/lms bootstrap"
        return 1
    fi
    return 0
}

# Display available LM Studio models with optional defaults highlighted
display_model_menu() {
    local default_reasoning="$1"
    local default_quick="$2"
    shift 2
    local models=("$@")

    if [ ${#models[@]} -eq 0 ]; then
        echo "No LM Studio models detected."
        return
    fi

    echo "Available LM Studio models:"
    local idx=1
    for model in "${models[@]}"; do
        local annotations=""
        if [ -n "$default_reasoning" ] && [ "$model" = "$default_reasoning" ]; then
            annotations="default reasoning"
        fi
        if [ -n "$default_quick" ] && [ "$model" = "$default_quick" ]; then
            if [ -n "$annotations" ]; then
                annotations="$annotations, default quick"
            else
                annotations="default quick"
            fi
        fi

        if [ -n "$annotations" ]; then
            printf "  [%d] %s (%s)\n" "$idx" "$model" "$annotations"
        else
            printf "  [%d] %s\n" "$idx" "$model"
        fi
        ((idx++))
    done
    printf "  [0] Skip loading for this slot\n"
    echo
}

# Prompt the user to choose a model by index, honoring defaults and skip
prompt_model_selection() {
    local role="$1"
    local default_model="$2"
    shift 2
    local models=("$@")
    local total=${#models[@]}

    if [ $total -eq 0 ]; then
        echo "$default_model"
        return 0
    fi

    local prompt_msg
    if [ -n "$default_model" ]; then
        prompt_msg="Select $role model by number [$default_model] (Enter for default, 0 to skip): "
    else
        prompt_msg="Select $role model by number (choose index, 0 to skip): "
    fi

    while true; do
        local response
        read -p "$prompt_msg" response

        if [ -z "$response" ]; then
            echo "$default_model"
            return 0
        fi

        if [[ "$response" =~ ^[0-9]+$ ]]; then
            local idx=$response
            if [ "$idx" -eq 0 ]; then
                echo ""
                return 0
            fi
            if [ "$idx" -ge 1 ] && [ "$idx" -le "$total" ]; then
                echo "${models[$((idx-1))]}"
                return 0
            fi
        fi

        echo "Invalid selection. Please enter a number between 0 and $total."
    done
}

# Start LMStudio server and load both models
ensure_lmstudio_server() {
    info "Checking LMStudio server (localhost:1234)..."
    
    # Check if CLI is available
    if ! check_lms_cli; then
        warn "Falling back to manual LMStudio startup instructions"
        warn "Please start LMStudio manually and load both models:"
        warn "1. Reasoning model: lmstudio-community/medgemma-27b-text-it-MLX-4bit"
        warn "2. Quick model: qwen/qwen3-4b-2507"
        return 1
    fi
    
    # Check if server is running
    if ! check_service_health "http://localhost:1234/v1/models" 3; then
        info "Starting LMStudio server..."
        if ! lms server start > /dev/null 2>&1; then
            error "Failed to start LMStudio server via CLI"
            return 1
        fi
        
        # Wait for server to start
        local retries=0
        while [ $retries -lt 30 ]; do
            if check_service_health "http://localhost:1234/v1/models" 3; then
                log "LMStudio server started successfully"
                break
            fi
            sleep 1
            ((retries++))
        done
        
        if [ $retries -eq 30 ]; then
            error "LMStudio server failed to start within 30 seconds"
            return 1
        fi
    else
        log "LMStudio server is already running"
    fi
    
    # Ensure both models are loaded
    ensure_dual_models_loaded
    return $?
}

# Load both medical models (reasoning + quick)
ensure_dual_models_loaded() {
    info "Verifying medical models are loaded..."

    # First, discover what models are actually downloaded
    info "Discovering available models..."
    local available_models=$(lms ls 2>/dev/null || echo "")

    if [ -z "$available_models" ]; then
        warn "Unable to list models. Make sure LM Studio CLI is properly configured."
        return 1
    fi

    # Prepare list of model ids for interactive selection
    local models_for_prompt=()
    while IFS= read -r model_id; do
        case "$model_id" in
            ""|"MODEL"|"Model"|"NAME"|"Name"|"ID"|"Id")
                continue
                ;;
        esac

        local exists=0
        for existing in "${models_for_prompt[@]}"; do
            if [ "$existing" = "$model_id" ]; then
                exists=1
                break
            fi
        done
        if [ $exists -eq 0 ]; then
            models_for_prompt+=("$model_id")
        fi
    done < <(echo "$available_models" | awk '{print $1}' | sed 's/\r$//')

    # Find reasoning model (medgemma variants)
    local reasoning_model=$(echo "$available_models" | grep -i "medgemma" | head -1 | awk '{print $1}')
    # Find quick model: prioritize qwen3-4b, then fall back to gemma variants
    local quick_model=$(echo "$available_models" | grep -iE "qwen.*3.*4b" | head -1 | awk '{print $1}')
    if [ -z "$quick_model" ]; then
        # Fallback: try gemma-3n variants
        quick_model=$(echo "$available_models" | grep -iE "gemma.*(3n|3-n|-3n|3_n)" | grep -v "medgemma" | head -1 | awk '{print $1}')
    fi

    if [ -z "$reasoning_model" ] && [ -z "$quick_model" ]; then
        # Final fallback: any gemma model
        quick_model=$(echo "$available_models" | grep -i "gemma" | grep -v "medgemma" | head -1 | awk '{print $1}')
    fi

    local reasoning_user_skipped=0
    local quick_user_skipped=0

    if [ -t 0 ] && [ ${#models_for_prompt[@]} -gt 0 ]; then
        echo
        info "Select LM Studio models to load:"
        display_model_menu "$reasoning_model" "$quick_model" "${models_for_prompt[@]}"

        local selected_reasoning
        selected_reasoning=$(prompt_model_selection "reasoning" "$reasoning_model" "${models_for_prompt[@]}")
        if [ -z "$selected_reasoning" ]; then
            reasoning_model=""
            reasoning_user_skipped=1
        else
            reasoning_model="$selected_reasoning"
        fi

        local selected_quick
        selected_quick=$(prompt_model_selection "quick" "$quick_model" "${models_for_prompt[@]}")
        if [ -z "$selected_quick" ]; then
            quick_model=""
            quick_user_skipped=1
        else
            quick_model="$selected_quick"
        fi
        echo
    fi

    log "üìã Selected LM Studio models:"
    if [ -n "$reasoning_model" ]; then
        log "   Reasoning: $reasoning_model"
    else
        if [ $reasoning_user_skipped -eq 1 ]; then
            warn "   Reasoning: skipped by user"
        else
            warn "   No MedGemma reasoning model found"
        fi
    fi
    if [ -n "$quick_model" ]; then
        log "   Quick: $quick_model"
    else
        if [ $quick_user_skipped -eq 1 ]; then
            warn "   Quick: skipped by user"
        else
            warn "   No Gemma quick model found"
        fi
    fi

    local reasoning_loaded=0
    local quick_loaded=0

    # Check what models are currently loaded
    local loaded_models=$(lms ps 2>/dev/null || echo "")
    if echo "$loaded_models" | grep -q "medgemma" 2>/dev/null; then
        reasoning_loaded=1
        log "‚úÖ Reasoning model already loaded"
    fi

    if echo "$loaded_models" | grep -qiE "(qwen.*3.*4b|gemma.*(3n|3-n|-3n|3_n))" 2>/dev/null; then
        quick_loaded=1
        log "‚úÖ Quick model already loaded"
    fi

    # Load models in parallel if both needed (saves ~2-3 minutes)
    local need_reasoning=$([[ $reasoning_loaded -eq 0 && ! -z "$reasoning_model" ]] && echo 1 || echo 0)
    local need_quick=$([[ $quick_loaded -eq 0 && ! -z "$quick_model" ]] && echo 1 || echo 0)

    if [ $need_reasoning -eq 1 ] && [ $need_quick -eq 1 ]; then
        info "Loading both models in parallel (faster startup)..."
        info "Reasoning: $reasoning_model | Quick: $quick_model"
        info "You can also load them manually in LM Studio - we'll detect automatically"

        local parallel_start=$(date +%s)

        # Start both loads in background
        (run_with_timeout 600 lms load "$reasoning_model" 2>&1) > /dev/null 2>&1 &
        local reasoning_pid=$!

        (run_with_timeout 300 lms load "$quick_model" 2>&1) > /dev/null 2>&1 &
        local quick_pid=$!

        # Single progress indicator for both
        (
            echo -n "   Loading both models"
            while true; do
                sleep 3
                local elapsed=$(($(date +%s) - parallel_start))
                local minutes=$((elapsed / 60))
                local seconds=$((elapsed % 60))
                echo -n " [${minutes}m ${seconds}s]."
            done
        ) &
        local progress_pid=$!

        # Poll for both models with unified timeout (10 min max)
        local poll_count=0
        while [ $poll_count -lt 200 ]; do
            sleep 3
            ((poll_count++))

            local loaded_models=$(lms ps 2>/dev/null || echo "")

            # Check reasoning model
            if [ $reasoning_loaded -eq 0 ] && echo "$loaded_models" | grep -q "medgemma" 2>/dev/null; then
                reasoning_loaded=1
                log "‚úÖ Reasoning model loaded"
            fi

            # Check quick model
            if [ $quick_loaded -eq 0 ] && echo "$loaded_models" | grep -qiE "(qwen.*3.*4b|gemma.*(3n|3-n|-3n|3_n))" 2>/dev/null; then
                quick_loaded=1
                log "‚úÖ Quick model loaded"
            fi

            # Exit when both loaded or both processes finished
            if [ $reasoning_loaded -eq 1 ] && [ $quick_loaded -eq 1 ]; then
                break
            fi

            # Check if processes finished
            local reasoning_done=$(! kill -0 $reasoning_pid 2>/dev/null && echo 1 || echo 0)
            local quick_done=$(! kill -0 $quick_pid 2>/dev/null && echo 1 || echo 0)

            if [ $reasoning_done -eq 1 ] && [ $quick_done -eq 1 ]; then
                # Final check
                local final_models=$(lms ps 2>/dev/null || echo "")
                echo "$final_models" | grep -q "medgemma" 2>/dev/null && reasoning_loaded=1
                echo "$final_models" | grep -qiE "(qwen.*3.*4b|gemma.*(3n|3-n|-3n|3_n))" 2>/dev/null && quick_loaded=1
                break
            fi
        done

        # Cleanup
        cleanup_background_jobs "$reasoning_pid" "$progress_pid"
        [ -n "$quick_pid" ] && kill -TERM "$quick_pid" 2>/dev/null || true
        wait "$quick_pid" 2>/dev/null || true
        echo ""

        local parallel_time=$(($(date +%s) - parallel_start))
        if [ $reasoning_loaded -eq 1 ] && [ $quick_loaded -eq 1 ]; then
            success "Both models loaded in parallel (took ${parallel_time}s)"
        elif [ $reasoning_loaded -eq 1 ] || [ $quick_loaded -eq 1 ]; then
            warn "Partial success after ${parallel_time}s - retrying failed model..."
        else
            warn "Parallel load timeout after ${parallel_time}s - retrying sequentially..."
        fi

    fi

    # Load reasoning model individually if still needed
    if [ $reasoning_loaded -eq 0 ] && [ ! -z "$reasoning_model" ]; then
        info "Loading reasoning model: $reasoning_model"
        info "This may take several minutes (timeout: 10 minutes)..."

        local start_time=$(date +%s)
        (
            echo -n "   Loading"
            while true; do
                sleep 3
                local elapsed=$(($(date +%s) - start_time))
                echo -n " [${elapsed}s]."
            done
        ) &
        local progress_pid=$!

        (run_with_timeout 600 lms load "$reasoning_model" 2>&1) > /dev/null 2>&1 &
        local load_pid=$!

        local poll_count=0
        while [ $poll_count -lt 200 ]; do
            sleep 3
            ((poll_count++))

            if lms ps 2>/dev/null | grep -q "medgemma" 2>/dev/null; then
                reasoning_loaded=1
                break
            fi

            if ! kill -0 $load_pid 2>/dev/null; then
                lms ps 2>/dev/null | grep -q "medgemma" 2>/dev/null && reasoning_loaded=1
                break
            fi
        done

        cleanup_background_jobs "$load_pid" "$progress_pid"
        echo ""

        if [ $reasoning_loaded -eq 1 ]; then
            log "‚úÖ Reasoning model loaded (took $(($(date +%s) - start_time))s)"
        else
            # Try short name fallback
            local short_name=$(echo "$reasoning_model" | cut -d'/' -f2)
            if [ ! -z "$short_name" ] && [ "$short_name" != "$reasoning_model" ]; then
                info "Trying short name: $short_name"
                run_with_timeout 300 lms load "$short_name" 2>&1 && reasoning_loaded=1
            fi
        fi
    fi

    # Load quick model individually if still needed
    if [ $quick_loaded -eq 0 ] && [ ! -z "$quick_model" ]; then
        info "Loading quick model: $quick_model"
        info "Timeout: 5 minutes..."

        local start_time=$(date +%s)
        (
            echo -n "   Loading"
            while true; do
                sleep 2
                echo -n " [$(($(date +%s) - start_time))s]."
            done
        ) &
        local progress_pid=$!

        (run_with_timeout 300 lms load "$quick_model" 2>&1) > /dev/null 2>&1 &
        local load_pid=$!

        local poll_count=0
        while [ $poll_count -lt 150 ]; do
            sleep 2
            ((poll_count++))

            if lms ps 2>/dev/null | grep -qiE "(qwen.*3.*4b|gemma.*(3n|3-n|-3n|3_n))" 2>/dev/null; then
                quick_loaded=1
                break
            fi

            if ! kill -0 $load_pid 2>/dev/null; then
                lms ps 2>/dev/null | grep -qiE "(qwen.*3.*4b|gemma.*(3n|3-n|-3n|3_n))" 2>/dev/null && quick_loaded=1
                break
            fi
        done

        cleanup_background_jobs "$load_pid" "$progress_pid"
        echo ""

        if [ $quick_loaded -eq 1 ]; then
            log "‚úÖ Quick model loaded (took $(($(date +%s) - start_time))s)"
        else
            # Try short name fallback
            local short_name=$(echo "$quick_model" | cut -d'/' -f2)
            if [ ! -z "$short_name" ] && [ "$short_name" != "$quick_model" ]; then
                info "Trying short name: $short_name"
                run_with_timeout 180 lms load "$short_name" 2>&1 && quick_loaded=1
            fi
        fi
    fi
    
    # Verify both models are loaded
    if [ $reasoning_loaded -eq 1 ] && [ $quick_loaded -eq 1 ]; then
        success "Both medical models loaded and ready!"
        return 0
    elif [ $reasoning_loaded -eq 1 ] || [ $quick_loaded -eq 1 ]; then
        warn "Partial success - some models loaded but not all"
        if [ $reasoning_loaded -eq 0 ]; then
            if [ $reasoning_user_skipped -eq 1 ]; then
                info "Reasoning model skipped by user selection"
            else
                warn "Missing reasoning model - complex analysis may be limited"
            fi
        fi
        if [ $quick_loaded -eq 0 ]; then
            if [ $quick_user_skipped -eq 1 ]; then
                info "Quick model skipped by user selection"
            else
                warn "Missing quick model - simple tasks may be slower"
            fi
        fi
        warn "Extension will work but with reduced capabilities"
        return 1
    else
        if [ $reasoning_user_skipped -eq 1 ] && [ $quick_user_skipped -eq 1 ]; then
            warn "No models were loaded because both selections were skipped"
            warn "You can load models later in LM Studio and rerun ./dev to detect them"
            return 1
        fi
        error "No models loaded successfully"
        error "Please check:"
        error "  1. Models are downloaded in LM Studio"
        error "  2. LM Studio server is running and accessible"
        error "  3. Sufficient system memory available"
        error "  4. Try loading models manually: lms load <model-name>"
        return 1
    fi
}

# Start MLX Whisper server if needed
ensure_whisper_server() {
    info "Checking MLX Whisper server (localhost:8001)..."

    if check_service_health "http://localhost:8001/v1/health"; then
        log "MLX Whisper server is already running and healthy"
        return 0
    fi

    if [ -f "./start-whisper-server.sh" ]; then
        info "Starting MLX Whisper server..."

        # Create a temporary log file for startup errors
        local whisper_log="/tmp/whisper-startup-$$.log"

        # Start the server and capture output
        # Show dependency installation but hide routine startup messages
        info "Installing/verifying Python dependencies..."
        (
            # Run startup script, show pip output but hide other noise
            ./start-whisper-server.sh 2>&1 | tee "$whisper_log" | grep -E "(Installing|Collecting|Successfully|Failed|ERROR|‚úÖ|‚ùå|üì¶|üåê)" || true
        ) &
        local whisper_pid=$!

        # Wait for server to start (longer timeout to allow for dependency installation)
        local retries=0
        while [ $retries -lt 60 ]; do
            if check_service_health "http://localhost:8001/v1/health"; then
                log "MLX Whisper server started successfully"
                rm -f "$whisper_log"
                return 0
            fi

            # Check if the process is still running
            if ! kill -0 $whisper_pid 2>/dev/null; then
                error "Failed to start MLX Whisper server - process died"
                if [ -f "$whisper_log" ]; then
                    error "Startup log (last 30 lines):"
                    tail -30 "$whisper_log" | while IFS= read -r line; do
                        error "  $line"
                    done
                    error ""
                    error "Common fixes:"
                    error "  1. Install dependencies manually: source venv-whisper/bin/activate && pip install -r requirements-whisper.txt"
                    error "  2. Check Python version: python3 --version (requires 3.8+)"
                    error "  3. Try recreating venv: rm -rf venv-whisper && ./start-whisper-server.sh"
                    rm -f "$whisper_log"
                fi
                return 1
            fi

            sleep 1
            ((retries++))
        done

        error "Failed to start MLX Whisper server - timeout after 60 seconds"
        if [ -f "$whisper_log" ]; then
            warn "Check startup log for details (last 30 lines):"
            tail -30 "$whisper_log" | while IFS= read -r line; do
                warn "  $line"
            done
            rm -f "$whisper_log"
        fi
        return 1
    else
        warn "MLX Whisper startup script not found: ./start-whisper-server.sh"
        warn "Please ensure MLX Whisper server is running manually"
        return 1
    fi
}

# Start DSPy server if needed  
ensure_dspy_server() {
    info "Checking DSPy server (localhost:8002)..."
    
    if check_service_health "http://localhost:8002/v1/health"; then
        log "DSPy server is already running and healthy"
        return 0
    fi
    
    if [ -f "./start-dspy-server.sh" ]; then
        info "Starting DSPy server..."
        ./start-dspy-server.sh start > /dev/null 2>&1
        
        # Wait for server to start
        local retries=0
        while [ $retries -lt 20 ]; do
            if check_service_health "http://localhost:8002/v1/health"; then
                log "DSPy server started successfully"
                return 0
            fi
            sleep 1
            ((retries++))
        done
        
        error "Failed to start DSPy server"
        return 1
    else
        error "DSPy startup script not found: ./start-dspy-server.sh"
        return 1
    fi
}

# Prepare Python environment for Operator Ingest
ensure_operator_ingest_env() {
    if [ ! -f "$OPERATOR_INGEST_REQ" ]; then
        warn "Operator Ingest requirements not found; skipping autostart"
        return 1
    fi

    if ! command -v python3 >/dev/null 2>&1; then
        warn "Cannot prepare Operator Ingest environment: python3 missing"
        return 1
    fi

    if [ ! -d "$OPERATOR_INGEST_VENV" ]; then
        info "Creating Operator Ingest virtual environment..."
        if ! python3 -m venv "$OPERATOR_INGEST_VENV" >/dev/null 2>&1; then
            warn "Failed to create Operator Ingest virtual environment"
            return 1
        fi
    fi

    local venv_pip="$OPERATOR_INGEST_VENV/bin/pip"
    local venv_python="$OPERATOR_INGEST_VENV/bin/python"
    if [ ! -x "$venv_pip" ] || [ ! -x "$venv_python" ]; then
        warn "Operator Ingest virtual environment missing pip/python"
        return 1
    fi

    local hash_file="$OPERATOR_INGEST_VENV/.requirements-hash"
    local req_hash current_hash
    req_hash=$(shasum "$OPERATOR_INGEST_REQ" | awk '{print $1}')
    [ -f "$hash_file" ] && current_hash=$(cat "$hash_file") || current_hash=""

    if [ "$req_hash" != "$current_hash" ]; then
        info "Installing/updating Operator Ingest dependencies..."
        if ! "$venv_pip" install -r "$OPERATOR_INGEST_REQ" >/dev/null 2>&1; then
            warn "Failed to install Operator Ingest dependencies"
            return 1
        fi
        echo "$req_hash" > "$hash_file"
    fi

    return 0
}

# Start Operator Ingest menubar app if not already running
start_operator_ingest_app() {
    info "Checking Operator Ingest menubar app (mac_daemon)..."

    if pgrep -f "mac_daemon.main" >/dev/null 2>&1; then
        log "Operator Ingest already running"
        return 0
    fi

    if ! ensure_operator_ingest_env; then
        warn "Skipping Operator Ingest autostart (environment not ready)"
        return 1
    fi

    local log_file="/tmp/operator-ingest-$(date +%s).log"
    local venv_python="$OPERATOR_INGEST_VENV/bin/python"

    if [ ! -x "$venv_python" ]; then
        warn "Operator Ingest python missing; skipping autostart"
        return 1
    fi

    info "Launching Operator Ingest menubar app (logs: $log_file)"

    local app_pid
    app_pid=$(
        cd "$SCRIPT_DIR" || exit 1
        nohup "$venv_python" -m mac_daemon.main >>"$log_file" 2>&1 &
        echo $!
    )

    if [ -n "$app_pid" ]; then
        echo "$app_pid" > /tmp/operator-ingest.pid
        log "Operator Ingest started (pid $app_pid)"
    else
        warn "Failed to start Operator Ingest (see $log_file)"
    fi
}

start_wardround_watcher() {
    info "Checking ward round watcher (TypeScript)..."

    if pgrep -f "wardround:watch" >/dev/null 2>&1; then
        log "Ward round watcher already running"
        return 0
    fi

    if ! command -v npm >/dev/null 2>&1; then
        warn "Skipping ward round watcher start (npm missing)"
        return 1
    fi

    local log_file="/tmp/wardround-watcher-$(date +%s).log"
    info "Launching ward round watcher (logs: $log_file)"

    local watcher_pid
    watcher_pid=$(
        cd "$SCRIPT_DIR" || exit 1
        nohup npm run wardround:watch >>"$log_file" 2>&1 &
        echo $!
    )

    if [ -n "$watcher_pid" ]; then
        echo "$watcher_pid" > /tmp/wardround-watcher.pid
        log "Ward round watcher started (pid $watcher_pid)"
    else
        warn "Failed to start ward round watcher (see $log_file)"
    fi
}

# Display comprehensive service status with model information
show_service_status() {
    echo
    success "=== Medical AI Development Environment ==="
    echo
    
    # LMStudio (Model Serving) with dual model status
    if check_service_health "http://localhost:1234/v1/models" 3; then
        log "‚úÖ LMStudio Server: http://localhost:1234"
        
        # Show loaded models with details
        if command -v lms &> /dev/null; then
            local models_info=$(lms ps 2>/dev/null || echo "")
            if [ ! -z "$models_info" ]; then
                # Detect reasoning model (medgemma)
                local reasoning_model=$(echo "$models_info" | grep -i "medgemma" | head -1 | awk '{print $1}')
                if [ ! -z "$reasoning_model" ]; then
                    echo -e "${GREEN}   ‚îú‚îÄ‚îÄ Reasoning Model: $reasoning_model ‚úÖ${NC}"
                else
                    echo -e "${YELLOW}   ‚îú‚îÄ‚îÄ Reasoning Model: Not loaded ‚ùå${NC}"
                fi

                # Detect quick model (qwen or gemma variants)
                local quick_model=$(echo "$models_info" | grep -iE "qwen.*3.*4b" | head -1 | awk '{print $1}')
                if [ -z "$quick_model" ]; then
                    quick_model=$(echo "$models_info" | grep -iE "gemma.*(3n|3-n|-3n|3_n)" | grep -v "medgemma" | head -1 | awk '{print $1}')
                fi
                if [ ! -z "$quick_model" ]; then
                    echo -e "${GREEN}   ‚îî‚îÄ‚îÄ Quick Model: $quick_model ‚úÖ${NC}"
                else
                    echo -e "${YELLOW}   ‚îî‚îÄ‚îÄ Quick Model: Not loaded ‚ùå${NC}"
                fi
            fi
        fi
    else
        warn "‚ùå LMStudio Server: http://localhost:1234 - NOT ACCESSIBLE"
    fi
    
    # MLX Whisper (Transcription)
    if check_service_health "http://localhost:8001/v1/health"; then
        log "‚úÖ MLX Whisper: http://localhost:8001"
    else
        warn "‚ùå MLX Whisper: http://localhost:8001 - NOT ACCESSIBLE"
    fi
    
    # DSPy Server (Optimization + SDK Streaming)
    if check_service_health "http://localhost:8002/v1/health"; then
        log "‚úÖ DSPy Server: http://localhost:8002"

        # Get DSPy server details including SDK status
        local dspy_status=$(curl -s "http://localhost:8002/v1/health" 2>/dev/null || echo "")
        if [ ! -z "$dspy_status" ]; then
            local stats_info=$(echo "$dspy_status" | python3 -c "
import sys, json
try:
    data = json.load(sys.stdin)
    agents = data.get('dspy', {}).get('enabled_agents', [])
    requests = data.get('stats', {}).get('requests_processed', 0)
    sdk_info = data.get('lmstudio_sdk', {})
    sdk_enabled = sdk_info.get('enabled', False)
    sdk_connected = sdk_info.get('connected', False)

    print(f'   ‚îú‚îÄ‚îÄ Enabled agents: {len(agents)}')
    print(f'   ‚îú‚îÄ‚îÄ Requests processed: {requests}')
    if sdk_enabled and sdk_connected:
        print(f'   ‚îî‚îÄ‚îÄ LM Studio SDK: ‚úÖ Connected (streaming enabled)')
    elif sdk_enabled:
        print(f'   ‚îî‚îÄ‚îÄ LM Studio SDK: ‚ö†Ô∏è  Enabled but not connected')
    else:
        print(f'   ‚îî‚îÄ‚îÄ LM Studio SDK: ‚ùå Disabled')
except:
    pass
" 2>/dev/null || echo "   ‚îî‚îÄ‚îÄ Status details unavailable")
            echo -e "${BLUE}$stats_info${NC}"
        fi
    else
        warn "‚ùå DSPy Server: http://localhost:8002 - NOT ACCESSIBLE"
    fi
    
    echo
    info "=== Quick Commands ==="
    echo "./dev                                    # Restart all servers"
    echo "curl http://localhost:1234/v1/models     # Check LMStudio models"
    echo "curl http://localhost:8001/v1/health     # Check MLX Whisper"  
    echo "curl http://localhost:8002/v1/health     # Check DSPy Server"
    echo
    info "=== Development Workflow ==="
    echo "npm run eval:angiogram                   # Evaluate with DSPy"
    echo "npm run optim:angiogram                  # GEPA optimization"
    echo "USE_DSPY=true npm run eval:quick-letter  # Enable DSPy mode"
    echo
}

# Main execution
main() {
    # Set up cleanup trap for temp files
    trap cleanup_on_exit EXIT

    log "üöÄ Starting Medical AI Development Environment..."
    echo

    local lmstudio_ok=0
    local whisper_ok=0
    local dspy_ok=0

    local interactive_shell=0
    if [ -t 0 ] && [ -t 1 ]; then
        interactive_shell=1
    fi

    # IMPORTANT: Complete LMStudio setup FIRST in interactive mode to avoid output conflicts
    if [ $interactive_shell -eq 1 ]; then
        # LMStudio with model selection (interactive - must complete first)
        if ensure_lmstudio_server; then
            echo "1" > /tmp/lmstudio-ok.$$
            lmstudio_ok=1
        else
            echo "0" > /tmp/lmstudio-ok.$$
            lmstudio_ok=0
        fi

        # Now start Whisper and DSPy in parallel (no user input needed)
        info "Starting Whisper and DSPy servers in parallel..."

        (ensure_whisper_server && echo "1" > /tmp/whisper-ok.$$ || echo "0" > /tmp/whisper-ok.$$) &
        local whisper_pid=$!

        (ensure_dspy_server && echo "1" > /tmp/dspy-ok.$$ || echo "0" > /tmp/dspy-ok.$$) &
        local dspy_pid=$!

        # Wait for both services
        wait $whisper_pid 2>/dev/null
        wait $dspy_pid 2>/dev/null
    else
        # Non-interactive: start all services in parallel (saves 13-70 seconds)
        info "Starting services in parallel..."

        (ensure_lmstudio_server && echo "1" > /tmp/lmstudio-ok.$$ || echo "0" > /tmp/lmstudio-ok.$$) &
        local lms_pid=$!

        (ensure_whisper_server && echo "1" > /tmp/whisper-ok.$$ || echo "0" > /tmp/whisper-ok.$$) &
        local whisper_pid=$!

        (ensure_dspy_server && echo "1" > /tmp/dspy-ok.$$ || echo "0" > /tmp/dspy-ok.$$) &
        local dspy_pid=$!

        # Wait for all services to complete
        wait $lms_pid 2>/dev/null
        wait $whisper_pid 2>/dev/null
        wait $dspy_pid 2>/dev/null
    fi

    # Read status from temp files
    [ -f /tmp/lmstudio-ok.$$ ] && lmstudio_ok=$(cat /tmp/lmstudio-ok.$$) || lmstudio_ok=0
    [ -f /tmp/whisper-ok.$$ ] && whisper_ok=$(cat /tmp/whisper-ok.$$) || whisper_ok=0
    [ -f /tmp/dspy-ok.$$ ] && dspy_ok=$(cat /tmp/dspy-ok.$$) || dspy_ok=0

    # Cleanup temp files
    rm -f /tmp/lmstudio-ok.$$ /tmp/whisper-ok.$$ /tmp/dspy-ok.$$
    
    # Show comprehensive status
    show_service_status
    
    # Summary
    local total_services=3
    local running_services=$((lmstudio_ok + whisper_ok + dspy_ok))
    
    if [ $running_services -eq $total_services ]; then
        success "üéâ Complete environment ready! All services running with dual models."
        success "Chrome extension can now use full Medical AI + DSPy SDK streaming capabilities."
    elif [ $running_services -gt 0 ]; then
        warn "‚ö†Ô∏è  $running_services/$total_services services running. Some functionality may be limited."
        warn "Check the status above and restart failed services manually."
    else
        error "‚ùå No services are running. Please check the logs and try again."
        error "Ensure LMStudio CLI is installed and models are available."
        exit 1
    fi

    start_operator_ingest_app
    start_wardround_watcher
}

# Handle command line arguments
case "${1:-}" in
    --help|-h)
        echo "Medical AI Development Environment Startup"
        echo ""
        echo "Usage: ./dev [OPTIONS]"
        echo ""
        echo "OPTIONS:"
        echo "  --help, -h     Show this help message"
        echo "  --status, -s   Show service status only"
        echo ""
        echo "This script starts all required services:"
        echo "  - LMStudio (localhost:1234) with dual models"
        echo "  - MLX Whisper (localhost:8001) for transcription"
        echo "  - DSPy Server (localhost:8002) for optimization"
        exit 0
        ;;
    --status|-s)
        show_service_status
        exit 0
        ;;
esac

# Trap signals for clean output
trap 'echo; error "Interrupted"; exit 1' INT TERM

# Run main function
main "$@"
